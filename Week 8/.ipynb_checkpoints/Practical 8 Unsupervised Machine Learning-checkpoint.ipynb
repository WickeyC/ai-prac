{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A: NLP Showcase with Supervised Learning\n",
    "\n",
    "## Sentiment Analysis\n",
    "\n",
    "▪ Sentiment analysis is a form of text classification wherein the text is classified either positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading movie_reviews dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as reviews\n",
    "\n",
    "# Print all file ids\n",
    "reviews.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips: Print file ids of all negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.fileids(\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews.fileids(\"neg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to print file ids of all positive reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How many positive reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the categories of all the files/reviews\n",
    "reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(reviews.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing positive movie_reviews\n",
    "\n",
    "### Tips: Print all the words in both positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all words in the 'movie_reviews' corpus\n",
    "reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to print all the words in a positive review named \"cv957_8737.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How many words are contained in this positive review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FreqDist()\n",
    "\n",
    "▪ The **FreqDist** function is used to find the frequency of words within a text. \n",
    "\n",
    "▪ It returns a **dictionary**, and hence we need to pass keys and values to get the data. \n",
    "\n",
    "<img src=\"freqdist.png\" width=\"500\">\n",
    "\n",
    "https://www.educative.io/answers/what-is-freqdist-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "sentence = 'The FreqDist function gives the user the frequency distribution of all the words in the text'\n",
    "\n",
    "freq_dist = FreqDist(word.lower() for word in word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to access all of the keys of a dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to access all of the values of a dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to access all of the keys and values of a dictionary at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the frequency of the word 'happy'\n",
    "FreqDist(reviews.words())['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = FreqDist(word.lower() for word in reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_common()\n",
    "\n",
    "▪ most_common() is a method that returns a list of tuples of (element, count) sorted by counts.\n",
    "\n",
    "https://note.nkmk.me/en/python-collections-counter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequency of the most common word in \"movie_reviews\"\n",
    "freq_dist.most_common()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequency of the least common word in \"movie_reviews\"\n",
    "freq_dist.most_common()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequencies of all words in \"movie_reviews\" in descending order\n",
    "freq_dist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequencies of all words in \"movie_reviews\" in ascending order\n",
    "freq_dist.most_common()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequency of 15 most common words in \"movie_reviews\" in descending order\n",
    "freq_dist.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the frequency of 15 most common words in \"movie_reviews\" in ascending order\n",
    "freq_dist.most_common(15)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested List Comprehension\n",
    "\n",
    "<img src=\"nested.png\" width=\"500\">\n",
    "\n",
    "▪ Outermost loop comes first, followed by innermost loop.\n",
    "\n",
    "https://www.youtube.com/watch?v=AzKV9NbtNJ0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = [\"Python\", \"Nested\"]\n",
    "text_2 = [\"List\", \"Comprehension\"]\n",
    "\n",
    "output = [(word_1, word_2) for word_1 in text_1 for word_2 in text_2]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[\"Python\", \"Nested\"], [\"List\", \"Comprehension\"]]\n",
    "\n",
    "output = [word for words in text for word in words]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [(x, y) for x in range(0, 3) for y in range(0, 3)]\n",
    "\n",
    "print(list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [(list(reviews.words(id)), cat) for cat in reviews.categories() for id in reviews.fileids(cat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2000 binary tuples in total\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo = [(len(d[0]), d[0][:2], d[1]) for d in docs[:10]]\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo = [(len(d[0]), d[0][:2], d[1]) for d in docs[:10]]\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of top 2000 most frequent words\n",
    "top_keys = [key for (key, value) in freq_dist.most_common(2000)]\n",
    "print(top_keys[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def review_features(doc):\n",
    "    # Convert a list of words to a set\n",
    "    doc_set = set(doc)\n",
    "    \n",
    "    # Create an empty dictionary\n",
    "    features = {}\n",
    "    \n",
    "    # Loop through the 2000 words\n",
    "    for word in top_keys:\n",
    "        # (word in doc_set) checks the presence of a word in doc_set and return either true or false\n",
    "        # feature is a dictionary that stores a key-value pair in the format of (word, true/false)\n",
    "        features[word] = (word in doc_set)\n",
    "        \n",
    "    return features\n",
    "\n",
    "data = [(review_features(doc), label) for (doc, label) in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the 1st review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][0]['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the last review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[-1][0]['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Training Data and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = len(data)\n",
    "train_count = int(.8 * data_count)\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:train_count]\n",
    "test_data = data[train_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = nltk.NaiveBayesClassifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", nltk.classify.accuracy(bayes, train_data))\n",
    "print(\"Test accuracy:\", nltk.classify.accuracy(bayes, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B: Unsupervised Machine Learning\n",
    "\n",
    "## Types of Machine Learning\n",
    "\n",
    "▪ Machine learning can be divided into two types: \n",
    "\n",
    "![](sml_usml.png)\n",
    "\n",
    "<img src=\"super.png\" width=\"500\">\n",
    "\n",
    "https://blog.bismart.com/en/classification-vs.-clustering-a-practical-explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Machine Learning\n",
    "\n",
    "▪ Unsupervised algorithms make inferences from datasets using only **input vectors without referring to known, or labelled, outcomes**.\n",
    "\n",
    "▪ The algorithm must figure out what it is viewing by itself and the objective is to discover interesting patterns in the data. \n",
    "\n",
    "▪ For instance, are there any subgroups or **\"clusters\"** among the data instances?\n",
    "\n",
    "<img src=\"unsuper.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "▪ Clustering can be considered the most important unsupervised learning problem.\n",
    "\n",
    "▪ A **centroid** is the imaginary or real location representing the center of the cluster.\n",
    "\n",
    "<img src=\"centroid.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The following 3 general clusters of consumers can let us understand our customers better:\n",
    "\n",
    "▪ Older customers spent very little\n",
    "\n",
    "▪ Middle-aged/older customers spent a lot\n",
    "\n",
    "▪ Middle-aged/younger customers spent a medium amount\n",
    "\n",
    "<img src=\"clustering.png\" width=\"350\">\n",
    "\n",
    "https://blog.dataiku.com/clustering-how-it-works-in-plain-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris Dataset \n",
    "\n",
    "### Understanding the dataset\n",
    "\n",
    "▪ **Iris Dataset**: The data set contains 3 classes with 50 instances each, and 150 instances in total, where each class refers to a type of iris plant.\n",
    "\n",
    "▪ **Class**: Iris Setosa, Iris Versicolour, Iris Virginica\n",
    "\n",
    "▪ **Data Format**: (sepal length, sepal width, petal length, petal width)\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/06/analyzing-decision-tree-and-k-means-clustering-using-iris-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"iris_flowers.png\" width=\"700\">\n",
    "\n",
    "<img src=\"iris.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C: Clustering with K-Means\n",
    "\n",
    "### Avoid memory leak when dealing with KMeans\n",
    "\n",
    "▪ A memory leak is the incorrect management of memory allocations by a computer program where the unneeded memory isn't released. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading the Dataset into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import some data to play with\n",
    "iris = pd.read_csv('iris_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 records\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the last 5 records\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species').size() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data visualization with mathplotlib\n",
    "\n",
    "▪ The plot() function is used to draw points (markers) in a diagram. \n",
    "\n",
    "▪ By default, the plot() function draws a line from point to point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris.plot(x = \"sepal_length\", y = \"sepal_width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot\n",
    "\n",
    "▪ Scatter plot is a graph in which the values of two variables are plotted along two axes.\n",
    "\n",
    "▪ It is the most basic type of plot that helps you visualize the relationship between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(iris['sepal_length'], iris['sepal_width'])\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Scatter plot on Iris dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot(kind = \"scatter\", x = \"sepal_length\", y = \"sepal_width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot(kind = \"scatter\", x = \"petal_length\", y = \"petal_width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andrews curves \n",
    "\n",
    "▪ We can use andrews_curves() to visualize high-dimensional or multivariate data by plotting the Andrews curves.\n",
    "\n",
    "▪ Each frame row represents a single curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import andrews_curves\n",
    "\n",
    "plt.figure(figsize = (15, 8)) \n",
    "andrews_curves(iris, \"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Splitting Data into Feature and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs into model\n",
    "X = iris.iloc[:, 0:4] \n",
    "\n",
    "# The label can be used to evaluate the model\n",
    "y = iris.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with K-means\n",
    "\n",
    "▪ K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n",
    "\n",
    "▪ K-Means will be used to find groups in the flower data.\n",
    "\n",
    "▪ The term \"K\" is a number that indicates how many clusters we need to create. E.g., K = 2 refers to two clusters.\n",
    "\n",
    "<img src=\"centroid.png\" width=\"600\">\n",
    "\n",
    "▪ The term \"means\" refers to averaging of the data; that is, finding the centroid.\n",
    "\n",
    "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the K-means model: Instructions\n",
    "\n",
    "▪ Step 1: Import KMeans from **sklearn.cluster**.\n",
    "\n",
    "▪ Step 2: Use KMeans() to create a KMeans instance called **km** to find the 3 clusters. \n",
    "\n",
    "▪ Step 3: To specify the number of clusters, use the **n_clusters** keyword argument.\n",
    "\n",
    "▪ Step 4: Use the **.fit()** method of model to fit the model to the array of points points.\n",
    "\n",
    "▪ Step 5: Use the **.predict()** method of model to predict the cluster labels of new_points, assigning the result to labels.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fitting the Model with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a KMeans instance with 3 clusters\n",
    "km = KMeans(n_clusters = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Accessing the Clusters of Data via labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the input training instances\n",
    "km.fit(X)\n",
    "\n",
    "labels = km.labels_\n",
    "\n",
    "# Print cluster labels of new_points\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fit_predict to fit model and obtain cluster labels: labels\n",
    "km_labels = km.fit_predict(X)\n",
    "\n",
    "print(km_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster_centers_\n",
    "\n",
    "▪ We use the **cluster_centers_** attribute to see the cluster centers (also called centroids). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the center points of the data\n",
    "centers = km.cluster_centers_\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# s = 100 represents the marker size \n",
    "# c = 'black' represents the marker colors\n",
    "plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s = 100, c = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'km_labels': km_labels, 'species': y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correspondence with iris species\n",
    "\n",
    "### crosstab()\n",
    "\n",
    "▪ Use the **pd.crosstab()** function on df['labels'] and df['varieties'] to count the number of times each iris species coincides with each cluster label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['km_labels'], y)\n",
    "#ct = pd.crosstab(df['km_labels'], df['species'])\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['km_labels'], df['species'], margins = True)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of Validation Techniques\n",
    "\n",
    "▪ Two techniques are used to validate the results for cluster learning:\n",
    "\n",
    "\\>>> **External validation**: This type of result validation can be carried out if true cluster labels are available.\n",
    "\n",
    "\\>>> **Internal validation**: Most of the methods of internal validation combine cohesion and separation to estimate the validation score.\n",
    "\n",
    "**[More Info: Clustering Metrics](https://scikit-learn.org/stable/modules/classes.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Validation: V-measure\n",
    "\n",
    "▪ **homogeneity**: each cluster contains only members of a single class.\n",
    "\n",
    "▪ **completeness**: all members of a given class are assigned to the same cluster.\n",
    "\n",
    "▪ V-measure score can be interpretated as an average of other two measures: homogeneity and completeness.\n",
    "\n",
    "https://www.kaggle.com/code/sashr07/unsupervised-learning-tutorial/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "labels_true = [0, 0, 0, 1, 1, 1]\n",
    "labels_pred_1 = [0, 0, 1, 1, 2, 2]\n",
    "labels_pred_2 = [0, 0, 0, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity = metrics.homogeneity_score(labels_true, labels_pred_1)  \n",
    "print(homogeneity)\n",
    "\n",
    "completeness = metrics.completeness_score(labels_true, labels_pred_1) \n",
    "print(completeness)\n",
    "\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "v_measure = v_measure_score(labels_true, labels_pred_1)  \n",
    "print(v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output order: Homogeneity, completeness and V-measure\n",
    "print('labels_pred_1:', metrics.homogeneity_completeness_v_measure(labels_true, labels_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following clustering is perfectly homogeneous but not complete\n",
    "print('labels_pred_2:', metrics.homogeneity_completeness_v_measure(labels_true, labels_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Iris-Dataset Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to measure homogeneity of clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to measure completeness of clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to measure v-measure score of clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How to measure all of the 3 scores of clustering at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring The Quality of Clustering\n",
    "\n",
    "▪ A good clustering has tight clusters where all samples in each cluster bunched together.\n",
    "\n",
    "### Inertia\n",
    "\n",
    "▪ Afer fitting a model with fit(), an attribute called **inertia_** is available.\n",
    "\n",
    "▪ Inertia calculates the sum of distances of all the points within a cluster from the centroid of that cluster.\n",
    "\n",
    "▪ The smaller the Inertia value, the more coherent are the different clusters. \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters = 3)\n",
    "km.fit(X)\n",
    "\n",
    "print(km.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the optimal K?\n",
    "\n",
    "▪ A good model is one with low inertia AND a low number of clusters (K). \n",
    "\n",
    "▪ However, this is a tradeoff because as K increases, inertia decreases.\n",
    "\n",
    "▪ To find the optimal K for a dataset, use the **Elbow method** to find the point where the decrease in inertia begins to slow. \n",
    "\n",
    "<img src=\"elbow.png\" width=\"500\">\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "▪ For each of the given values of k, perform the following steps:\n",
    "\n",
    "\\>>> Create a KMeans instance called model with k clusters.\n",
    "\n",
    "\\>>> Fit the model to the grain data samples.\n",
    "\n",
    "\\>>> Append the value of the inertia_ attribute of model to the list inertias.\n",
    "\n",
    "https://www.kaggle.com/sashr07/unsupervised-learning-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 7)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters = k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "    \n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C: Exercise\n",
    "\n",
    "## 1.0 Mean Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out the number of estimated clusters by Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Mean Shift model and generate the ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the score using v_measure_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example output:__ 0.6994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Gaussian mixture models (GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit GMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the score using *v_measure_score()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example output:__ 0.8997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Agglomerative Hierarchical  Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example output:__ 0.7701"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

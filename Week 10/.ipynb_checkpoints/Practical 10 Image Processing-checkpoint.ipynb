{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 7: Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A: Introduction to Image Processing\n",
    "\n",
    "### What is Image?\n",
    "\n",
    "<img src=\"pixel.png\" width=\"350\">\n",
    "\n",
    "▪ An image is an array/matrix of square pixels (picture elements) arranged in columns and rows, usually represented in one of the following:\n",
    "\n",
    "\\>>> **Grayscale**: A pixel is an integer with a value between 0 to 255 (0 is completely black and 255 is completely white).\n",
    "\n",
    "\\>>> **RGB**: A pixel is made up of 3 integers between 0 to 255 (the integers represent the intensity of red, green, and blue).\n",
    "\n",
    "\\>>> **RGBA**: It is an extension of RGB with an added alpha field, which represents the opacity of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Image Processing?\n",
    "\n",
    "▪ Image processing is a method to perform some operations on an image, to convert the image to a digital aspect and perform certain functions on it, in order to get an enhanced image or to extract some useful information from it. \n",
    "\n",
    "### Libraries involved in Image Processing: OpenCV\n",
    "\n",
    "▪ OpenCV (Open Source Computer Vision Library) is one of the most widely used libraries to perform image processing and video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of OpenCV\n",
    "\n",
    "▪ When you run **import cv2** and an error message like **ModuleNotFoundError: No module named 'cv2'** is returned, it means that OpenCV library is not available.\n",
    "\n",
    "▪ To install OpenCV, run the following command in Anaconda Prompt: **pip install opencv-python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section B: Basic Operations on Images\n",
    "\n",
    "### Reading an image\n",
    "\n",
    "▪ **cv2.imread()** returns a 2D or 3D array based on the number of color channels present in the image. \n",
    "\n",
    "▪ For a binary or greyscale image, 2D array is sufficient; but for a colored image, a 3D array is needed.\n",
    "\n",
    "▪ The syntax of **cv2.imread()** is given as: **cv2.imread(path, flag)** where the **path** has to be the complete absolute path to the image, and the **flag** is optional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"image1.jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an image with matplotlib's plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an Image in a Window \n",
    "\n",
    "▪ Use **cv2.imshow()** function to display/show an image in the specified window.\n",
    "\n",
    "▪ The syntax of **imshow()** function is: **cv2.imshow(window_name, image)** where **window_name** is the title of the window in which the image numpy.ndarray will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image1', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What happened when the above code is run?\n",
    "\n",
    "▪ **cv2.imshow()** won't work properly without the use of **cv2.waitKey()**.\n",
    "\n",
    "https://docs.opencv.org/2.4/modules/highgui/doc/user_interface.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an Image for a Period of Time \n",
    "\n",
    "▪ **cv2.waitkey()** function allows users to display a window for a given milliseconds.\n",
    "\n",
    "▪ If **30** is passed in the argument such as **waitKey(30)**, it will keep the frame active for 30 ms and then close it automatically.\n",
    "\n",
    "https://machinelearningknowledge.ai/opencv-cv2-waitkey-tutorial-with-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the numbers 1, 2 and 3 at an interval of 5000 ms or 5 seconds\n",
    "print(\"1\")\n",
    "cv2.waitKey(5000)\n",
    "print(\"2\")\n",
    "cv2.waitKey(5000)\n",
    "print(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"image1.jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image1', image)\n",
    "cv2.waitKey(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destrying all Windows \n",
    "\n",
    "▪ **cv2.destroyAllWindows()** destroys the window showing image.\n",
    "\n",
    "▪ Not using **cv2.destroyAllWindows()** at the end of the script might make the window opened to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.imshow('image1', image)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an Image forever \n",
    "\n",
    "▪ **cv2.waitkey()** function also allows users to display a window until any key is pressed.\n",
    "\n",
    "▪ If **0** is passed in the argument such as **waitKey(0)**, then it will wait until a key is pressed.\n",
    "\n",
    "https://machinelearningknowledge.ai/opencv-cv2-waitkey-tutorial-with-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image1', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Properties of an Image from shape and size\n",
    "\n",
    "▪ The **shape** property returns tuple representing (**height**, **width**, **number_of_channels**) where\n",
    "\n",
    "\\>>> **height** represents the number of pixel rows in the image.\n",
    "\n",
    "\\>>> **width** represents the number of pixel columns in the image.\n",
    "\n",
    "\\>>> **number_of_channels** represents the number of components used to represent each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Dimension    :', image.shape)\n",
    "print('Image Height       :', image.shape[0])\n",
    "print('Image Width        :', image.shape[1])\n",
    "print('Number of Channels :', image.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the output of print(image)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the output of print(image[0])?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the output of print(image[0][0])?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the output of print(image[0][0][0])?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading an image in different ways \n",
    "\n",
    "▪ The syntax of **cv2.imread()** is given as: **cv2.imread(path, flag)** where the **path** has to be the complete absolute path to the image, and the **flag** is optional. \n",
    "\n",
    "▪ One of the following possible values can be passed for the **flag**:\n",
    "\n",
    "\\>>> **cv2.IMREAD_COLOR** or **1** reads the image with RGB colors but no transparency channel. \n",
    "\n",
    "\\>>> **cv2.IMREAD_GRAYSCALE** or **0** reads the image as grey image. \n",
    "\n",
    "\\>>> **cv2.IMREAD_UNCHANGED** or **-1** reads the image as is from the source. \n",
    "\n",
    "https://pythonexamples.org/python-opencv-read-image-cv2-imread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_1 = cv2.imread(\"image1.jpg\") \n",
    "image_2 = cv2.imread(\"image1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "image_3 = cv2.imread(\"image1.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "cv2.imshow('RGB colour image', image_1)\n",
    "cv2.imshow('greyscale image', image_2)\n",
    "cv2.imshow('original image', image_3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale Image vs. Coloured Image\n",
    "\n",
    "<img src=\"imread.png\" width=\"500\">\n",
    "\n",
    "▪ **cv2.imread()** returns a 2D or 3D matrix based on the number of color channels present in the image. \n",
    "\n",
    "▪ For a binary or greyscale image, 2D array is sufficient; but for a colored image, a 3D array is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale Images\n",
    "\n",
    "▪ Greyscale images are **single-channeled images** in which **each pixel carries only information about the intensity of light**. \n",
    "\n",
    "▪ When the pixel value is 0 it is black and when the pixel value is 255 it is white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Greyscale image\")\n",
    "print(\"Dimensions:\", image_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 2d array\n",
    "print(image_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coloured Images\n",
    "\n",
    "▪ Coloured images, also called RGB images, are three channeled images.\n",
    "\n",
    "▪ Each pixel is made up of 3 channels, with each channel representing a colour. \n",
    "\n",
    "▪ The 0th index has the intensity of red light, the 1st index the intensity of green light and the 2nd index, the intensity of blue light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coloured image\")\n",
    "print(\"Dimensions:\", image_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 3d array\n",
    "print(image_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Channel from Colored Image\n",
    "\n",
    "▪ The **split()** function is used to split the channels, and the outputs are **single-channeled images**. \n",
    "\n",
    "▪ These **single-channeled images** are also greyscale images.\n",
    "\n",
    "https://pythonexamples.org/python-opencv-extract-green-channel-from-color-image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, g, r = cv2.split(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue channel\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green channel\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red channel\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Single-Channeled Images\n",
    "\n",
    "▪ Check the RGB values of the image using the **Paint** program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('balls2.png')\n",
    "  \n",
    "# Displaying the original BGR image\n",
    "cv2.imshow('Original_Image', image)\n",
    "  \n",
    "# Using cv2.split() to split channels of coloured image \n",
    "b, g, r = cv2.split(image)\n",
    "  \n",
    "# Displaying Blue/Green/Red channel image separately\n",
    "cv2.imshow(\"Model Blue Image\", b)\n",
    "cv2.imshow(\"Model Green Image\", g)\n",
    "cv2.imshow(\"Model Red Image\", r)\n",
    "  \n",
    "# Waits for user to press any key\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # destroys the window showing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing an Image into the File Directory\n",
    "\n",
    "▪ We can use **cv2.imwrite()** to save an image to a local storage.\n",
    "\n",
    "▪ The syntax of **cv2.imwrite()** function is: **cv2.imwrite(path, image)**\n",
    "\n",
    "▪ It returns a boolean value: **True** if the image is successfully written and **False** if the image is not written successfully to the local path specified.\n",
    "\n",
    "https://pythonexamples.org/python-opencv-cv2-imwrite-save-image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Save the matrix/array (which is img) as an image file\n",
    "is_written = cv2.imwrite('image2.png', b)\n",
    "\n",
    "if is_written:\n",
    "    print('Image is successfully saved as file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('image2.png')\n",
    "cv2.imshow('Blue channeled image', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing an Image\n",
    "\n",
    "▪ We can use **cv2.resize()** to resize an image.\n",
    "\n",
    "▪ The syntax of **cv2.resize()** function is **cv2.resize(src, dsize, fx, fy, interpolation)**\n",
    "\n",
    "\\>>> **src** is the source, original or input image in the form of numpy array\n",
    "\n",
    "\\>>> **dsize** is the desired size of the output image, given as tuple\n",
    "\n",
    "\\>>> **fx** is the scaling factor along X-axis or Horizontal axis\n",
    "\n",
    "\\>>> **fy** is the scaling factor along Y-axis or Vertical axis\n",
    "\n",
    "\\>>> **interpolation** refers to different methods of resizing the image (i.e., **INTER_NEAREST**, **INTER_LINEAR**, **INTER_AREA**, **INTER_CUBIC** and **INTER_LANCZOS4**)\n",
    "\n",
    "https://pythonexamples.org/python-opencv-cv2-resize-image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"balls.jpg\") \n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the percent by which the image is resized\n",
    "scale_percent = 50\n",
    "\n",
    "# Calculate the 50 percent of original dimensions\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "\n",
    "# dsize\n",
    "dsize = (width, height)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(image, dsize, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Resized ', resized)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing With a Scaling Factor\n",
    "\n",
    "▪ Scaling Factor or Scale Factor is usually a number that scales or multiplies some quantity, in our case the width and height of the image. \n",
    "\n",
    "▪ It helps keep the aspect ratio intact and preserves the display quality. \n",
    "\n",
    "▪ So the image does not appear distorted, while you are upscaling or downscaling it.\n",
    "\n",
    "https://learnopencv.com/image-resizing-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling down the image 0.75 times by specifying both the scaling factors\n",
    "resized_1 = cv2.resize(image, None, fx = 0.5, fy = 0.25, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Scaling down the image 0.75 times by specifying both the scaling factors\n",
    "resized_2 = cv2.resize(image, None, fx = 1.2, fy = 1.2, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Showing the original image and resized image\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Resized (-)', resized_1)\n",
    "cv2.imshow('Resized (+)', resized_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping an Image\n",
    "\n",
    "▪ An image can be cropped using NumPy array slicing. \n",
    "\n",
    "▪ To slice an array, the **start index** and **end index** of the first and the second dimension needs to be specified. \n",
    "\n",
    "\\>>> The first dimension is the number of rows or the height of the image.\n",
    "\n",
    "\\>>> The second dimension is the number of columns or the width of the image.\n",
    "\n",
    "▪ The syntax is: **cropped = img\\[start_row:end_row, start_col:end_col\\]**\n",
    "\n",
    "https://learnopencv.com/cropping-an-image-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "# Cropping an image\n",
    "cropped_image = image[100:385, 190:375]\n",
    "\n",
    "# Display original and cropped image\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Cropped\", cropped_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Text on Image\n",
    "\n",
    "▪ We can write text on image with **putText()** that accepts the following arguments:\n",
    "\n",
    "\\>>> The image on which we can write the text\n",
    "\n",
    "\\>>> The text we want to write on image\n",
    "\n",
    "\\>>> The position of the text: distance along horizontal and vertical axis from top left corner of the image\n",
    "\n",
    "\\>>> font family\n",
    "\n",
    "\\>>> font size\n",
    "\n",
    "\\>>> font color\n",
    "\n",
    "\\>>> font stroke width\n",
    "\n",
    "https://pythonexamples.org/python-opencv-write-text-on-image-puttext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "# The 1st value indicates the point on x-axis, and the 2nd values indicates the point on the y-axis\n",
    "position = (200, 50)\n",
    "\n",
    "output = cv2.putText(image, \"Lenna\", position, cv2.FONT_HERSHEY_SIMPLEX, 1, (209, 80, 0), 3)\n",
    "\n",
    "cv2.imshow(\"Image with text\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating an Image with a Straight Line\n",
    "\n",
    "▪ We can annotate the image with a color line using the **line()** function. \n",
    "\n",
    "▪ The syntax for the line() function is: **line(image, start_point, end_point, color, thickness)**\n",
    "\n",
    "https://learnopencv.com/annotating-images-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "# Create a copy of the image\n",
    "image_line = image.copy()\n",
    "\n",
    "# Specify the start and end points to draw a line that is 180-pixels long horizontally on the image, from point A to B \n",
    "point_1 = (200, 300)\n",
    "point_2 = (380, 350)\n",
    "\n",
    "# Draw a line on image\n",
    "cv2.line(image_line, point_1, point_2, (255, 255, 0), thickness = 3, lineType = cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Modified', image_line)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating an Image with a Circle\n",
    "\n",
    "▪ We can annotate the image with a circle using the **circle()** function. \n",
    "\n",
    "▪ The syntax for the circle() function is: **circle(image, center_coordinates, radius, color, thickness)**\n",
    "\n",
    "https://learnopencv.com/annotating-images-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "image_circle = image.copy()\n",
    "\n",
    "# Define the center point of the circle\n",
    "circle_center = (290, 275)\n",
    "\n",
    "# Define the radius of the circle\n",
    "radius = 120\n",
    "\n",
    "# Draw a circle on the image\n",
    "cv2.circle(image_circle, circle_center, radius, (0, 0, 255), thickness = -1, lineType = cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Modified', image_circle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating an Image with a Rectangle\n",
    "\n",
    "▪ We can draw a rectangle on the image using the **rectangle()** function.\n",
    "\n",
    "▪ The syntax for the rectangle() function is: **rectangle(image, start_point, end_point, color, thickness)**\n",
    "\n",
    "https://learnopencv.com/annotating-images-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "image_rectangle = image.copy()\n",
    "\n",
    "# Define the starting and end points of the rectangle (x, y)\n",
    "start_point = (200, 200)\n",
    "end_point = (375, 390)\n",
    "\n",
    "# Draw the rectangle on the image\n",
    "cv2.rectangle(image_rectangle, start_point, end_point, (255, 0, 0), thickness= -1, lineType=cv2.LINE_8)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Modified', image_rectangle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding or Blending Two Images\n",
    "\n",
    "▪ We can add or blend two images using the **cv2.addWeighted()** function.\n",
    "\n",
    "▪ The syntax of addWeighted() is **addWeighted(src1, alpha, src2, beta, gamma)**\n",
    "\n",
    "\\>>> **src1** and **src2** are input image arrays \n",
    "\n",
    "\\>>> **alpha** and **beta** are the corresponding weights to be considered while performing the weighted addition\n",
    "\n",
    "\\>>> **gamma** is static weight that will be added to all the pixels of the image\n",
    "\n",
    "https://pythonexamples.org/python-opencv-add-blend-two-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_1 = cv2.imread('yellow.png', cv2.IMREAD_COLOR)\n",
    "source_2 = cv2.imread('Lenna.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# add or blend the images\n",
    "merged = cv2.addWeighted(source_1, 0.9, source_2, 0.1, 0.0)\n",
    "\n",
    "cv2.imshow('Original_1', source_1)\n",
    "cv2.imshow('Original_2', source_2)\n",
    "cv2.imshow('Merged', merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C: Image Processing\n",
    "\n",
    "### Image Filtering Using Convolution \n",
    "\n",
    "▪ Convolution is the process of transforming an image by applying a kernel over each pixel and its local neighbors across the entire image.\n",
    "\n",
    "▪ In image processing, a **convolution kernel** is a 2D matrix that is used to filter images. \n",
    "\n",
    "▪ Such kernels can be used to perform mathematical operations on each pixel of an image to achieve a desired effect like **blurring** or **sharpening** an image. \n",
    "\n",
    "<img src=\"convolution.jpg\">\n",
    "\n",
    "<img src=\"convolution2.jpg\">\n",
    "\n",
    "https://medium.com/@bdhuma/6-basic-things-to-know-about-convolution-daef5e1bc411\n",
    "\n",
    "https://dev.to/sandeepbalachandran/machine-learning-convolution-with-color-images-2p41\n",
    "\n",
    "### Sharpening an Image Using Custom 2D-Convolution Kernels\n",
    "\n",
    "▪ To sharpen an image, define a custom 2D kernel, and then use the **filter2D(src, ddepth, kernel)** function to apply the convolution operation to the image where:\n",
    "\n",
    "\n",
    "\\>>> The first argument is the source image.\n",
    "\n",
    "\\>>> The second argument is ddepth, which indicates the depth of the resulting image. A value of -1 indicates that the final image will also have the same depth as the source image.\n",
    "\n",
    "\\>>> The third argument is the kernel, which we apply to the source image.\n",
    "\n",
    "https://learnopencv.com/image-filtering-using-convolution-in-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Lenna.png')\n",
    "\n",
    "image_resized = cv2.resize(image, None, fx = 0.7, fy = 0.7, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a sharpening kernel\n",
    "kernel = np.array([[0,  -1,  0],\n",
    "                   [-1,  5, -1],\n",
    "                   [0,  -1,  0]])\n",
    "\n",
    "image_sharpened = cv2.filter2D(src = image_resized, ddepth = -1, kernel = kernel)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Sharpened', image_sharpened)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurring an Image using a Custom 2D-Convolution Kernel\n",
    "\n",
    "▪ We can also use a custom kernel to blur an image. \n",
    "\n",
    "▪ Divide each element of the kernel by the number of elements in the kernel to ensure that all the values are normalized (stay within the range of \\[0, 1\\]). \n",
    "\n",
    "https://learnopencv.com/image-filtering-using-convolution-in-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = np.ones((5, 5), np.float32) / 25\n",
    "kernel_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 5×5 average blurring kernel consisting of only ones\n",
    "kernel_2 = np.ones((5, 5), np.float32) / 25\n",
    "\n",
    "image_blurred_2 = cv2.filter2D(src = image_resized, ddepth = -1, kernel = kernel_2)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Blurred', image_blurred_2)\n",
    "    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_1 = np.ones((3, 3), np.float32) / 9\n",
    "kernel_3 = np.ones((9, 9), np.float32) / 81\n",
    "\n",
    "image_blurred_1 = cv2.filter2D(src = image_resized, ddepth = -1, kernel = kernel_1)\n",
    "image_blurred_3 = cv2.filter2D(src = image_resized, ddepth = -1, kernel = kernel_3)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Blurred 3x3', image_blurred_1)\n",
    "cv2.imshow('Blurred 5x5', image_blurred_2)\n",
    "cv2.imshow('Blurred 9x9', image_blurred_3)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurring an Image Using OpenCV’s Built-In Function\n",
    "\n",
    "▪ We can also blur an image, using OpenCV’s built-in **blur()** function, without having to specifically define a kernel.\n",
    "\n",
    "▪ The **blur()** function will then internally create a specified size of blur kernel, and apply it to the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the blur function to blur an image where ksize is the kernel size\n",
    "image_blurred_1 = cv2.blur(src = image_resized, ksize = (5, 5)) \n",
    "image_blurred_2 = cv2.blur(src = image_resized, ksize = (9, 9)) \n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Blurred 5x5', image_blurred_1)\n",
    "cv2.imshow('Blurred 9x9', image_blurred_2)\n",
    "    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Gaussian Blurring to an Image in OpenCV\n",
    "\n",
    "▪ The **GaussianBlur()** function requires four input arguments:\n",
    "\n",
    "\\>>> The first argument, **src**, specifies the source image that you want to filter.\n",
    "\n",
    "\\>>> The second argument is **ksize**, which defines the size of the Gaussian kernel. Here, we are using a 5×5 kernel.\n",
    "\n",
    "\\>>> The final two arguments are **sigmaX** and **sigmaY**, which are both set to 0. \n",
    "\n",
    "<img src=\"gaussian.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_blurred_1 = cv2.GaussianBlur(src = image_resized, ksize = (5, 5), sigmaX = 0, sigmaY = 0)\n",
    "gaussian_blurred_2 = cv2.GaussianBlur(src = image_resized, ksize = (9, 9), sigmaX = 0, sigmaY = 0)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Gaussian Blurred 5x5', gaussian_blurred_1)\n",
    "cv2.imshow('Gaussian Blurred 9x9', gaussian_blurred_2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Median Blurring to an Image in OpenCV\n",
    "\n",
    "▪ The **medianBlur()** function has two required arguments:\n",
    "\n",
    "\\>>> The first is the source image.\n",
    "\n",
    "\\>>> The second is the kernel size, which must be an odd, positive integer.\n",
    "\n",
    "<img src=\"median.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_blurred_1 = cv2.medianBlur(src = image_resized, ksize = 5)\n",
    "median_blurred_2 = cv2.medianBlur(src = image_resized, ksize = 9)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Median Blurred 5x5', median_blurred_1)\n",
    "cv2.imshow('Median Blurred 9x9', median_blurred_2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection \n",
    "\n",
    "▪ Edge detection is an image-processing technique, which is used to identify the boundaries (edges) of objects, or regions within an image. \n",
    "\n",
    "▪ Below is an image of edges being detected in an image:\n",
    "\n",
    "![](edges.png)\n",
    "\n",
    "https://pyimagesearch.com/2021/05/12/image-gradients-with-opencv-sobel-and-scharr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection Algorithm\n",
    "\n",
    "▪ The Canny Edge Detection algorithm is one of the most popular edge-detection methods introduced by John F. Canny in 1986.\n",
    "\n",
    "▪ The syntax of OpenCV Canny Edge Detection is **edges = cv2.Canny(image, threshold1, threshold2)**.\n",
    "\n",
    "▪ To apply the Canny() function, we only need to supply the two thresholds used by the Canny Edge Detection algorithm.\n",
    "\n",
    "<img src=\"thresholds.png\" width=\"300\">\n",
    "\n",
    "https://pyimagesearch.com/2021/05/12/opencv-edge-detection-cv2-canny/\n",
    "\n",
    "https://www.tutorialkart.com/opencv/python/image-edge-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ori = cv2.imread('Lenna.png')\n",
    "# image = cv2.imread('book1.png')\n",
    "# image = cv2.imread('shapes.png')\n",
    "\n",
    "image_resized = cv2.resize(image_ori, None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Blurring an image to reduce noise before computing edges In Canny Edge Detection\n",
    "imaged_blurred = cv2.medianBlur(src=image_resized, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Blurred', imaged_blurred)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_1 = cv2.Canny(image_resized, 100, 200)\n",
    "edges_2 = cv2.Canny(imaged_blurred, 100, 200)\n",
    "# edges = cv2.Canny(image, 100, 255)\n",
    "# edges = cv2.Canny(image, 50, 150)\n",
    "# edges = cv2.Canny(image, 150, 200)\n",
    "# edges = cv2.Canny(image, 50, 250)\n",
    "\n",
    "cv2.imshow('Original', image_resized)\n",
    "cv2.imshow('Edge (Original)', edges_1)\n",
    "cv2.imshow(\"Edge (Blurred)\", edges_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological Transformations\n",
    "\n",
    "▪ Morphological operations are simple transformations used to increase/decrease the size of objects as well as closing/opening gaps between objects in images.\n",
    "\n",
    "▪ Morphological operations examine an image with a **structuring element**, which is a type of kernel or mask.\n",
    "\n",
    "https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Digit2.png')\n",
    "\n",
    "cv2.imshow('Digit', image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion\n",
    "\n",
    "▪ An erosion removes pixels on object boundaries in an image.\n",
    "\n",
    "<img src=\"erosion.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2 structuring elements full of ones\n",
    "kernel_1 = np.ones((3, 3), np.uint8) \n",
    "kernel_2 = np.ones((4, 4), np.uint8) \n",
    "\n",
    "# Erosion\n",
    "# The 3rd parameter is the number of iterations, that determines how much we want to erode/dilate a given image\n",
    "erosion1 = cv2.erode(image, kernel_1, iterations = 1)\n",
    "erosion2 = cv2.erode(image, kernel_1, iterations = 2)\n",
    "erosion3 = cv2.erode(image, kernel_2, iterations = 1)\n",
    "\n",
    "cv2.imshow('original', image)\n",
    "cv2.imshow('erosion1', erosion1)\n",
    "cv2.imshow('erosion2', erosion2)\n",
    "cv2.imshow('erosion3', erosion3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n",
    "\n",
    "▪ Dilation adds pixels to the boundaries of objects in an image. \n",
    "\n",
    "<img src=\"dilation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structuring element\n",
    "kernel_1 = np.ones((3, 3), np.uint8)\n",
    "kernel_2 = np.ones((11, 11), np.uint8)\n",
    "\n",
    "# Dilation\n",
    "dilation1 = cv2.dilate(image, kernel_1, iterations = 1)\n",
    "dilation2 = cv2.dilate(image, kernel_1, iterations = 3)\n",
    "dilation3 = cv2.dilate(image, kernel_2, iterations = 1)\n",
    "\n",
    "cv2.imshow('original', image)\n",
    "cv2.imshow('dilation1', dilation1)\n",
    "cv2.imshow('dilation2', dilation2)\n",
    "cv2.imshow('dilation3', dilation3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening\n",
    "\n",
    "▪ Opening is just a name of erosion followed by dilation. \n",
    "\n",
    "<img src=\"opening.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structuring element\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Opening\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('original', image)\n",
    "cv2.imshow('opening', opening)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.17.6 Closing\n",
    "\n",
    "▪ Closing is the reverse of opening: dilation followed by erosion. \n",
    "\n",
    "<img src=\"closing.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structuring element\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Closing\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow('original', image)\n",
    "cv2.imshow('closing', closing)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner detection using Harris corner detector\n",
    "\n",
    "▪ A corner may be defined as the intersection of two edges, where an edge represents a sharp change in picture brightness.\n",
    "\n",
    "<img src=\"corner.jpg\">\n",
    "\n",
    "▪ Corner detection can be done using the **cv2.cornerHarris(image, blockSize, ksize, k, borderType)** function where:\n",
    "\n",
    "\\>>> **image**: the input image, a single-channel 8-bit or floating-point image,\n",
    "\n",
    "\\>>> **blockSize**: the size of the neighbourhood considered for corner detection,\n",
    "\n",
    "\\>>> **ksize**: Aperture parameter of the Sobel derivative used,\n",
    "\n",
    "\\>>> **k**: harris detector free parameter in the equation,\n",
    "\n",
    "\\>>> **borderType**: pixel extrapolation method.\n",
    "\n",
    "https://www.etutorialspoint.com/index.php/317-harris-corner-detection-using-python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# image = cv2.imread('book1.png')\n",
    "image = cv2.imread('chessboard.png')\n",
    "\n",
    "image_resized = cv2.resize(image, None, fx = 0.4, fy = 0.4, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Convert the imported image in grayscale\n",
    "gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Modify the input image data type to 32 bits float\n",
    "gray = np.float32(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Harris Corner Detector method to detect the corners\n",
    "dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "\n",
    "# Use the cv2.dilate() method to adds pixels to the corners of objects\n",
    "dst = cv2.dilate(dst, None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverting back to the original image\n",
    "# Threshold for an optimal value, it may vary depending on the image\n",
    "image_resized[dst > 0.01 * dst.max()] = [0, 0, 255] \n",
    "\n",
    "cv2.imshow('corner_detection', image_resized)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image inpainting \n",
    "\n",
    "▪ Image inpainting is a form of image restoration which can be done using one of the following inpainting algorithms:\n",
    "\n",
    "\\>>> cv2.INPAINT_TELEA: An image inpainting technique based on the fast marching method (Telea, 2004)\n",
    "\n",
    "\\>>> cv2.INPAINT_NS: Navier-stokes, Fluid dynamics, and image and video inpainting (Bertalmío et al., 2001)\n",
    "\n",
    "▪ When applying inpainting with OpenCV, two images are needed:\n",
    "\n",
    "▪ The input damaged image we wish to inpaint and restore\n",
    "\n",
    "▪ The mask image that indicates where in the image the damage is. This image should have the same spatial dimensions (width and height) as the input image. \n",
    "\n",
    "https://pyimagesearch.com/2020/05/18/image-inpainting-with-opencv-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Lenna_noise.png')\n",
    "mask = cv2.imread('Lenna_mask.png', 0)\n",
    "\n",
    "output = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
    "# output = cv2.inpaint(image, mask, 3, cv2.INPAINT_NS)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Recovery\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('boy1.png')\n",
    "mask = cv2.imread('boy2.png', 0)\n",
    "\n",
    "output = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
    "# output = cv2.inpaint(image, mask, 3, cv2.INPAINT_NS)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "cv2.imshow(\"Recovery\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "▪ The following code shows how to segment different elements from the map images (\"map.png\") and visualize it in different windows such as lake, road, field, and housing area. \n",
    "\n",
    "<img src=\"map_segment.png\">\n",
    "\n",
    "▪ Use different range of RGB values to distinguish one segment from another, and then extract them.\n",
    "\n",
    "▪ Check the RGB values for the map using **Paint** program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_ori = cv2.imread('map.png')\n",
    "\n",
    "image = cv2.resize(image_ori, None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inRange()\n",
    "\n",
    "▪ The inRange() function returns an array of elements equal to 255 or 0 (a pixel is set to 255 if it lies within the boundaries specified, otherwise it is set to 0.)\n",
    "\n",
    "▪ Its syntax is **resultarray = inRange(sourcearray, lowerboundarray, upperboundarray)** where:\n",
    "\n",
    "\\>>> sourcearray is the array whose elements are to be compared with the arrays representing upper bounds and lower bounds.\n",
    "\n",
    "\\>>> lowerboundarray is the array consisting of elements representing lower bounds.\n",
    "\n",
    "\\>>> upperboundarray is the array consisting of elements representing upper bounds.\n",
    "\n",
    "https://www.educba.com/opencv-inrange/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the river\n",
    "lower_bound_river = np.array([253, 197, 133]) \n",
    "upper_bound_river = np.array([254, 233, 208]) \n",
    "\n",
    "mask_river = cv2.inRange(image, lower_bound_river, upper_bound_river)\n",
    "cv2.imshow('mask', mask_river)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 2 images together by using the AND operation onto each pixel\n",
    "river = cv2.bitwise_and(image, image)\n",
    "cv2.imshow('mask', river)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the river\n",
    "lower_bound = np.array([253, 197, 133]) \n",
    "upper_bound = np.array([254, 233, 208]) \n",
    "\n",
    "mask_river = cv2.inRange(image, lower_bound, upper_bound)\n",
    "river = cv2.bitwise_and(image, image, mask = mask_river)\n",
    "\n",
    "cv2.imshow('map', image)\n",
    "cv2.imshow(\"river\", river)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the road\n",
    "lower_bound_road = np.array([100, 205, 245])\n",
    "upper_bound_road = np.array([170, 230, 265])\n",
    "\n",
    "mask_road = cv2.inRange(image, lower_bound_road, upper_bound_road)\n",
    "road = cv2.bitwise_and(image, image, mask = mask_road)\n",
    "\n",
    "cv2.imshow('map', image)\n",
    "cv2.imshow(\"road\", road)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the field\n",
    "lower_bound_field = np.array([179, 220, 204])\n",
    "upper_bound_field = np.array([199, 240, 224])\n",
    "\n",
    "mask_field = cv2.inRange(image, lower_bound_field, upper_bound_field)\n",
    "field = cv2.bitwise_and(image, image, mask = mask_field)\n",
    "\n",
    "cv2.imshow('map', image)\n",
    "cv2.imshow(\"field\", field)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the building\n",
    "lower_bound_building = np.array([228, 214, 235])\n",
    "upper_bound_building = np.array([248, 254, 255])\n",
    "\n",
    "mask_building = cv2.inRange(image, lower_bound_building, upper_bound_building)\n",
    "building = cv2.bitwise_and(image, image, mask = mask_building)\n",
    "\n",
    "cv2.imshow('map', image)\n",
    "cv2.imshow(\"building\", building)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section D: Getting Started with Videos\n",
    "\n",
    "### Reading a Video from the Local Drive\n",
    "\n",
    "▪ Reading and writing videos in OpenCV is very similar to reading and writing images. \n",
    "\n",
    "▪ All we need to do is loop over all the frames in a video sequence, and then process one frame at a time using the following functions:\n",
    "\n",
    "\\>>> Use the **VideoCapture()** function to create a VideoCapture object to read the video file.\n",
    "\n",
    "\\>>> Use the **isOpened()** function to confirm the video file was opened successfully by returning a boolean value.  \n",
    "\n",
    "\\>>> Use the **read()** function to read one frame at a time, and returns a tuple (the 1st element is a boolean and the 2nd element is a frame). \n",
    "\n",
    "\\>>> Use the **release()** function to release captured frame frame-by-frame.\n",
    "\n",
    "https://learnopencv.com/reading-and-writing-videos-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid_capture = cv2.VideoCapture('motion.mp4')\n",
    "\n",
    "if (vid_capture.isOpened() == False):\n",
    "    print(\"Error opening the video file\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid_capture.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(100) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing a Video from the Webcam\n",
    "\n",
    "▪ **VideoCapture()**: If our PC has a built-in webcam, then the device index for the camera will be \"0\". \n",
    "\n",
    "▪ If it has more than one camera connected to it, then the device index associated with each additional camera is incremented (e.g. 1, 2, etc). \n",
    "\n",
    "https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid_capture = cv2.VideoCapture(0)\n",
    "\n",
    "if (vid_capture.isOpened() == False):\n",
    "    print(\"Error accessing the camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid_capture.read() \n",
    "\n",
    "    if ret == True:\n",
    "        cv2.imshow('Web Cam', frame) \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "            \n",
    "vid_capture.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a Video onto the Local Drive\n",
    "\n",
    "▪ To write a video file, use **VideoWriter()** to create AVI or MP4 formats, with the following fourcc specifications:\n",
    "\n",
    "\\>>> AVI: cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "\n",
    "\\>>> MP4: cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "https://learnopencv.com/reading-and-writing-videos-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# vid_capture = cv2.VideoCapture(0)\n",
    "vid_capture = cv2.VideoCapture('motion.mp4')\n",
    "\n",
    "# Retrieve the frame width and height\n",
    "frame_width = int(vid_capture.get(3)) # Can replace 3 with CAP_PROP_FRAME_WIDTH\n",
    "frame_height = int(vid_capture.get(4)) # Can replace 4 with CAP_PROP_FRAME_HEIGHT\n",
    "frame_size = (frame_width, frame_height)\n",
    "fps = 20\n",
    "\n",
    "# output = cv2.VideoWriter('output_video.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 20, frame_size)\n",
    "output = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'XVID'), 20, frame_size)\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid_capture.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the frame to the output files\n",
    "        output.write(frame)\n",
    "\n",
    "        cv2.imshow('Web Cam', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "vid_capture.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "\n",
    "Implement an intrusion detection system which will continually loop the program and fire an alarm when Intrusion is True (you may use the sample video and declare an intrusion as \"1\" when intrusion is true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
